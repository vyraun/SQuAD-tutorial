{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train.dat', 'rb') as outfile:\n",
    "    save_obj = pickle.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contexts, questions, answers, vocab_size = \\\n",
    "save_obj['contexts'].toarray(),\\\n",
    "save_obj['questions'].toarray(),\\\n",
    "save_obj['answers'].toarray(),\\\n",
    "save_obj['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, merge\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model(context_len, question_len, vocab_size, embed_dim=100):\n",
    "    context_input = Input(shape=(context_len,), dtype='int32', name='context_input')\n",
    "    \n",
    "    context_embedding = Embedding(output_dim=embed_dim, input_dim=vocab_size, dropout=0.3)(context_input)\n",
    "    # output: (samples, context_len, embedding_dim)\n",
    "        \n",
    "    question_input = Input(shape=(question_len,), dtype='int32', name='question_input')\n",
    "    question_embedding = Embedding(output_dim=embed_dim, input_dim=vocab_size, dropout=0.3)(question_input)\n",
    "    # output: (samples, question_len, embedding_dim)\n",
    "    \n",
    "    merged = merge([context_embedding, question_embedding], mode='dot', dot_axes=[2, 2])\n",
    "    # output: (samples, context_len, question_len)\n",
    "    \n",
    "    lstm_merge = LSTM(128, return_sequences=True)(merged)\n",
    "    # output: (samples, context_len, 128)\n",
    "    \n",
    "    predictions = TimeDistributed(Dense(2, activation='softmax'))(lstm_merge)\n",
    "    \n",
    "    model = Model(input=[context_input, question_input], output=predictions)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "model = build_model(contexts.shape[1], questions.shape[1], vocab_size, embed_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = answers.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "rows, cols= answers.shape\n",
    "answers = np_utils.to_categorical(answers.reshape((rows*cols,)), nb_classes = 2).reshape((rows, cols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3706, 2)\n",
      "(3706,)\n"
     ]
    }
   ],
   "source": [
    "print(answers[0].shape)\n",
    "print(contexts[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "model.fit([contexts, questions], answers, nb_epoch=50, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
